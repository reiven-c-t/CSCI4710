{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#483D8B\">\n",
    "<h1  align=\"center\">Map Reduce</h1>\n",
    "<h2  align=\"center\">Lab 2</h2>\n",
    "<h4 align=\"center\">\n",
    "INET4710 Spring 2018<br>\n",
    "Submitted by (your name here)</h4>\n",
    "</font>\n",
    "\n",
    "---------------\n",
    "\n",
    "Lab Objectives\n",
    "-\tUnderstand the map-reduce programming framework\n",
    "-\tLearn how to write a simple map reduce pipeline in Python (single input, single output).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify this Map Reduce class for lab 2 word count \n",
    "import sys\n",
    "import io\n",
    "import string\n",
    "\n",
    "class MapReduce:\n",
    "    def __init__(self):\n",
    "        # unsorted dictionary of keys and values\n",
    "        self.intermediate = dict()\n",
    "        self.result = []\n",
    "\n",
    "        \n",
    "    def emitIntermediate(self, key, value):\n",
    "      self.intermediate.setdefault(key, [])       \n",
    "      self.intermediate[key].append(value)\n",
    "\n",
    "    def emit(self, value):\n",
    "      self.result.append(value) \n",
    "\n",
    "    def execute(self, data, mapper, reducer):\n",
    "        for record in data:\n",
    "            mapper(record)\n",
    "\n",
    "        # shuffle stage sorts keys\n",
    "        for key in sorted(self.intermediate.keys()):\n",
    "#            print(key, self.intermediate[key])\n",
    "            reducer(key, self.intermediate[key])\n",
    "\n",
    "        # sorts final result (needed if multiple reducers)\n",
    "        self.result.sort()\n",
    "        for item in self.result:\n",
    "            print ( item )\n",
    "\n",
    "mapReducer = MapReduce()\n",
    "\n",
    "\n",
    "def mapper(record):\n",
    "    #Start writing the Map code here\n",
    "    print (\"mapper\")\n",
    "    \n",
    "def reducer(key, list_of_values):\n",
    "    #Start writing the Reduce code here\n",
    "    print (\"reducer\")   \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "  inputData = []\n",
    "  for line in sys.stdin:\n",
    "   inputData.append(line)\n",
    "  mapReducer.execute(inputData, mapper, reducer)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Map Reduce Program:  Word Count\n",
    "\n",
    "Modified from  “A Simple Example in Python” <br> at\n",
    "https://www.princeton.edu/researchcomputing/computational-hardware/hadoop/mapred-tut/\n",
    "\n",
    "**1. Create a text file with the text in the poem **\n",
    "[The Road Not Taken](https://www.poetryfoundation.org/poems/44272/the-road-not-taken)\n",
    "\n",
    "**2. In the code section below, write code to read the file and write code for the mapper  function. The code should **\n",
    "-\tCount words\n",
    "-   Run successfully\n",
    "-   Remove punctuation\n",
    "-\tConvert text to lower case\n",
    "\n",
    "\n",
    "This URLs may be helpful:<br>\n",
    "[stdin encoding](http://stackoverflow.com/questions/16549332/python-3-how-to-specify-stdin-encoding)<br>\n",
    "[map reduce example](https://github.com/cielavenir/procon/blob/master/hackerrank/map-reduce-advanced-count-number-of-friends.py)\n",
    "[python dict](https://www.tutorialspoint.com/python/python_dictionary.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import string\n",
    "\n",
    "class MapReduce:\n",
    "    def __init__(self):\n",
    "        self.intermediate = dict()\n",
    "        self.result = []\n",
    "   \n",
    "\n",
    "    def emitIntermediate(self, key, value):\n",
    "      self.intermediate.setdefault(key, [])       \n",
    "      self.intermediate[key].append(value)\n",
    "\n",
    "    def emit(self, value):\n",
    "      self.result.append(value) \n",
    "\n",
    "    def execute(self, data, mapper, reducer):\n",
    "        for record in data:\n",
    "            mapper(record)\n",
    "\n",
    "        for key in sorted(self.intermediate.keys()):\n",
    "#            print(key, self.intermediate[key])\n",
    "            reducer(key, self.intermediate[key])\n",
    "\n",
    "        self.result.sort()\n",
    "        for item in self.result:\n",
    "            print ( item )\n",
    "\n",
    "mapReducer = MapReduce()\n",
    "\n",
    "def mapper(line):\n",
    "    # add mapper code below\n",
    "    \n",
    "def reducer(key, list_of_values):\n",
    "    mapReducer.emit((key,len(list_of_values)))\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "  inputData = []\n",
    "  file = open(\"C:\\myClasses\\INET4710_2018Spring\\Labs\\Lab2\\TheRoadNotTaken.txt\", \"r\")\n",
    "  for line in file:\n",
    "   inputData.append(line)\n",
    "  mapReducer.execute(inputData, mapper, reducer)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Map Reduce Program:  Natural Language Toolkit\n",
    "\n",
    "Following along with the tutorial:\n",
    "Let us consider a more advanced example, which is based on word counting. A typical text mining or natural language processing task involves following steps:\n",
    " \n",
    "1. Tokenization\n",
    "2. Text normalization\n",
    "3. Stop word removal\n",
    "4. Stemming\n",
    "\n",
    "For more information about NLTK, browse to https://pypi.python.org/pypi/nltk\n",
    "\n",
    "NLTK is already installed as part of the Anaconda installation; however, we need to download the stopwords corpus before running the tutorial NLTK program. Please refer to the lab 2 assignment for instructions about downloading the stopwords corpus.\n",
    "\n",
    "For this section:\n",
    "\n",
    "1. Download the stopwords corpus.\n",
    "2. Modify the NLTK code given in the lab 2 assignment to run in the Map Reduce class for this lab.\n",
    "3. Run the code on \"The Path Not Taken\" poem file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import string\n",
    "import re\n",
    "import nltk.tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class MapReduce:\n",
    "    def __init__(self):\n",
    "        self.intermediate = dict()\n",
    "        self.result = []\n",
    "   \n",
    "\n",
    "    def emitIntermediate(self, key, value):\n",
    "      self.intermediate.setdefault(key, [])       \n",
    "      self.intermediate[key].append(value)\n",
    "\n",
    "    def emit(self, value):\n",
    "      self.result.append(value) \n",
    "\n",
    "    def execute(self, data, mapper, reducer):\n",
    "        for record in data:\n",
    "            mapper(record)\n",
    "\n",
    "        for key in sorted(self.intermediate.keys()):\n",
    "#            print(key, self.intermediate[key])\n",
    "            reducer(key, self.intermediate[key])\n",
    "\n",
    "        self.result.sort()\n",
    "        for item in self.result:\n",
    "            print ( item )\n",
    "\n",
    "mapReducer = MapReduce()\n",
    "\n",
    "def mapper(line):\n",
    "    # add mapper code below\n",
    "    \n",
    "def reducer(key, list_of_values):\n",
    "     mapReducer.emit((key,len(list_of_values)))\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "  # initialize stop words\n",
    "  stops = set(stopwords.words('english'))\n",
    "\n",
    "  inputData = []\n",
    "  file = open(\"C:\\myClasses\\INET4710_2018Spring\\Labs\\Lab2\\TheRoadNotTaken.txt\", \"r\")\n",
    "  for line in file:\n",
    "   inputData.append(line)\n",
    "  mapReducer.execute(inputData, mapper, reducer)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Map Reduce Program:  pyspark Word Count\n",
    "\n",
    "\n",
    "1. Modify the code at\n",
    "https://github.com/apache/spark/blob/master/examples/src/main/python/wordcount.py\n",
    "2. Run the code on text read from the \"The Path Not Taken\" file\n",
    "\n",
    "The code should:\n",
    "- Count words using pyspark\n",
    "- Remove punctuation\n",
    "- Convert text to lower case\n",
    "- Run successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from operator import add\n",
    "\n",
    "spark_path = \"C:\\spark\\spark-2.2.1-bin-hadoop2.7\"\n",
    "\n",
    "os.environ['SPARK_HOME'] = spark_path\n",
    "os.environ['HADOOP_HOME'] = spark_path\n",
    "\n",
    "sys.path.append(spark_path + \"/bin\")\n",
    "sys.path.append(spark_path + \"/python\")\n",
    "sys.path.append(spark_path + \"/python/pyspark/\")\n",
    "sys.path.append(spark_path + \"/python/lib\")\n",
    "sys.path.append(spark_path + \"/python/lib/pyspark.zip\")\n",
    "sys.path.append(spark_path + \"/python/lib/py4j-0.10.4-src.zip\")\n",
    "\n",
    "import pyspark\n",
    "\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    " \n",
    "# local[*]  Run Spark locally with as many worker threads \n",
    "#           as logical cores on your machine\n",
    "# getOrCreate() Gets an existing SparkSession or, if there \n",
    "#           is no existing one, creates a new one based on the \n",
    "#           options set in this builder\n",
    "\n",
    "spark = SparkSession \\\n",
    "     .builder \\\n",
    "     .master(\"local[*]\") \\\n",
    "     .appName(\"lab1\") \\\n",
    "     .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile('C:\\myClasses\\INET4710_2018Spring\\Labs\\Lab2\\TheRoadNotTaken.txt')\n",
    "\n",
    "# add code below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
