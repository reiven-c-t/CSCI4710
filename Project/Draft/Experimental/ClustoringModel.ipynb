{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Experimental Model\n",
    "\n",
    "This note includes clustoring model.\n",
    "What I do is clustoring post_message of all_data to find similar comments.\n",
    "\n",
    "But, I might not do clustoring as final submission because the result seems meaningless or difficult to evaluate.\n",
    "\n",
    "If I could do, I also attoch these experiment to final notebook. But, in this mean time, I omit these model from main notebook. Still atouch them when I could not finish new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result shape compare:  (500, 10) (498, 5)\nresult shape compare:  (500, 10) (496, 5)\nresult shape compare:  (500, 10) (500, 5)\nresult shape compare:  (500, 10) (500, 5)\nresult shape compare:  (500, 10) (500, 5)\n"
     ]
    }
   ],
   "source": [
    "# format function definition copied from main note\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz as tz\n",
    "import pickle\n",
    "from os.path import exists\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def format_data(df, page_label):\n",
    "    \"\"\"\n",
    "    function to clean dataframes.\n",
    "    this function drop rows which contains NA, \n",
    "    and drop page_url, source, post_link column\n",
    "    instead of dropping page_url and source, I add page_label text.\n",
    "    \n",
    "    also create datetime column and remove date, time, time_zone\n",
    "    :param df: \n",
    "    :param page_label:  \n",
    "    :return df: \n",
    "    \"\"\"\n",
    "    past_shape = df.shape\n",
    "    df = df.dropna(axis=0, how='any')\n",
    "    df = df.drop(['page_url', 'source', 'post_link', 'post_type'], axis=1)\n",
    "    df['page_label'] = page_label\n",
    "    df = df.reset_index()  # reset index for datetime append operation\n",
    "\n",
    "    datetime_list = list()\n",
    "    for i in range(df.shape[0]):\n",
    "        # need correct numerical index for code below.\n",
    "        dt_str = '%s %s %s' % (df['date'][i], df['time'][i], df['time_zone'][i])\n",
    "        dt_str = dt_str.strip()  # need strip to remove last blank character.\n",
    "        try:\n",
    "            dt_parsed = datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S %Z%z')\n",
    "            CT = tz.timezone('America/Chicago')\n",
    "            dt_parsed = dt_parsed.astimezone(CT)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print('error happen :%s;' % dt_str)\n",
    "            dt_parsed = None\n",
    "        datetime_list.append(dt_parsed)\n",
    "\n",
    "    df['datetime'] = datetime_list\n",
    "    df = df.drop(['index', 'date', 'time', 'time_zone'], axis=1)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    show = True\n",
    "    if show:\n",
    "        print('result shape compare: ', past_shape, df.shape)\n",
    "    return df\n",
    "\n",
    "# make term document matrix\n",
    "\n",
    "\n",
    "data_path = '/Users/reiven/Documents/Python/CSCI4710/Project/Data'\n",
    "binary_path = '/Users/reiven/Documents/Python/CSCI4710/Project/binary_file'\n",
    "tfidf_vectorizer_path = \"/Users/reiven/Documents/Python/CSCI4710/Project/binary_file/tfidf_vectorizer.pkl\"\n",
    "\n",
    "blacktivist_data = pd.read_csv(path.join(data_path, 'blacktivist.csv'))\n",
    "being_patriotic_data = pd.read_csv(path.join(data_path, 'being_patriotic.csv'))\n",
    "# heart_of_texas_data = pd.read_csv(path.join(data_path, 'heart_of_texas.csv'))\n",
    "lgbt_united_data = pd.read_csv(path.join(data_path, 'lgbt_united.csv'))\n",
    "secured_borders_data = pd.read_csv(path.join(data_path, 'secured_borders.csv'))\n",
    "united_muslims_of_america_data = pd.read_csv(path.join(data_path, 'united_muslims_of_america.csv'))\n",
    "\n",
    "# format all data with format_data()\n",
    "blacktivist = format_data(blacktivist_data, 'blacktivist')\n",
    "being_patriotic = format_data(being_patriotic_data, 'being_patriotic')\n",
    "lgbt_united = format_data(lgbt_united_data, 'lgbt_united')\n",
    "secured_borders = format_data(secured_borders_data, 'secured_borders')\n",
    "united_muslims_of_america = format_data(united_muslims_of_america_data, 'united_muslims')\n",
    "\n",
    "all_data = pd.concat([blacktivist, being_patriotic, lgbt_united, secured_borders, united_muslims_of_america])\n",
    "\n",
    "if exists(tfidf_vectorizer_path):\n",
    "    with open(tfidf_vectorizer_path, \"rb\") as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "        f.close()\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        use_idf=True,\n",
    "        analyzer='word',\n",
    "        stop_words='english',\n",
    "        lowercase=True\n",
    "    )\n",
    "    vectorizer.fit(all_data['post_message'])\n",
    "    with open(tfidf_vectorizer_path, \"wb\") as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "        f.close()\n",
    "\n",
    "post_message_tfidf_matrix = vectorizer.transform(all_data['post_message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 1 1 1 4 1 1 4 4]\n"
     ]
    }
   ],
   "source": [
    "# KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "# choice 5 because the data are from 5 resources\n",
    "model = MiniBatchKMeans(n_clusters=5)\n",
    "model.fit(post_message_tfidf_matrix)\n",
    "predict_label = model.predict(post_message_tfidf_matrix)\n",
    "print(predict_label[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# choice 5 because the data are from 5 resources\n",
    "model = DBSCAN()\n",
    "predict_label = model.fit_predict(post_message_tfidf_matrix)\n",
    "\n",
    "\n",
    "print(predict_label[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "matrix_array_path = \"/Users/reiven/Documents/Python/CSCI4710/Project/binary_file/matrix_array.pkl\"\n",
    "GMM_path = \"/Users/reiven/Documents/Python/CSCI4710/Project/binary_file/gmm.pkl\"\n",
    "\n",
    "# if exists(matrix_array_path):\n",
    "#     with open(matrix_array_path, \"rb\") as f:\n",
    "#         matrix_array = pickle.load(f)\n",
    "# else: \n",
    "#     matrix_array = matrix.toarray()\n",
    "#     with open(matrix_array_path, \"wb\") as f:\n",
    "#         pickle.dump(matrix_array, f)\n",
    "  \n",
    "matrix_array = post_message_tfidf_matrix.toarray()  \n",
    "if exists(GMM_path):\n",
    "    with open(GMM_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "else: \n",
    "    model = GaussianMixture(n_components=5, covariance_type='spherical')\n",
    "    model.fit(matrix_array)\n",
    "    with open(GMM_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "predict_label = model.predict(matrix_array)\n",
    "\n",
    "print(predict_label[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
